{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# from utils.datasets import autosplit\n",
    "# from utils.general import download, xyxy2xywhn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_labels(fname=Path('xView/xView_train.geojson')):\n",
    "    # Convert xView geoJSON labels to YOLO format\n",
    "    path = fname.parent\n",
    "    with open(fname) as f:\n",
    "        print(f'Loading {fname}...')\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Make dirs\n",
    "    labels = Path(path / 'labels' / 'train')\n",
    "    os.system(f'rm -rf {labels}')\n",
    "    labels.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # xView classes 11-94 to 0-59\n",
    "    xview_class2index = [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 1, 2, -1, 3, -1, 4, 5, 6, 7, 8, -1, 9, 10, 11,\n",
    "                        12, 13, 14, 15, -1, -1, 16, 17, 18, 19, 20, 21, 22, -1, 23, 24, 25, -1, 26, 27, -1, 28, -1,\n",
    "                        29, 30, 31, 32, 33, 34, 35, 36, 37, -1, 38, 39, 40, 41, 42, 43, 44, 45, -1, -1, -1, -1, 46,\n",
    "                        47, 48, 49, -1, 50, 51, -1, 52, -1, -1, -1, 53, 54, -1, 55, -1, -1, 56, -1, 57, -1, 58, 59]\n",
    "\n",
    "    shapes = {}\n",
    "    for feature in tqdm(data['features'], desc=f'Converting {fname}'):\n",
    "        p = feature['properties']\n",
    "        if p['bounds_imcoords']:\n",
    "            id = p['image_id']\n",
    "            file = path / 'train_images' / id\n",
    "            if file.exists():  # 1395.tif missing\n",
    "                try:\n",
    "                    box = np.array([int(num) for num in p['bounds_imcoords'].split(\",\")])\n",
    "                    assert box.shape[0] == 4, f'incorrect box shape {box.shape[0]}'\n",
    "                    cls = p['type_id']\n",
    "                    cls = xview_class2index[int(cls)]  # xView class to 0-60\n",
    "                    assert 59 >= cls >= 0, f'incorrect class index {cls}'\n",
    "\n",
    "                    # Write YOLO label\n",
    "                    if id not in shapes:\n",
    "                        shapes[id] = Image.open(file).size\n",
    "                    box = xyxy2xywhn(box[None].astype(np.float), w=shapes[id][0], h=shapes[id][1], clip=True)\n",
    "                    with open((labels / id).with_suffix('.txt'), 'a') as f:\n",
    "                        f.write(f\"{cls} {' '.join(f'{x:.6f}' for x in box[0])}\\n\")  # write label.txt\n",
    "                except Exception as e:\n",
    "                    print(f'WARNING: skipping one label for {file}: {e}')\n",
    "\n",
    "\n",
    "# Download manually from https://challenge.xviewdataset.org\n",
    "# dir = Path(yaml['path'])  # dataset root dir\n",
    "# urls = ['https://d307kc0mrhucc3.cloudfront.net/train_labels.zip',  # train labels\n",
    "#         'https://d307kc0mrhucc3.cloudfront.net/train_images.zip',  # 15G, 847 train images\n",
    "#         'https://d307kc0mrhucc3.cloudfront.net/val_images.zip']  # 5G, 282 val images (no labels)\n",
    "# download(urls, dir=dir, delete=False)\n",
    "\n",
    "# Convert labels\n",
    "# convert_labels(dir / 'xView_train.geojson')\n",
    "\n",
    "# # Move images\n",
    "# images = Path(dir / 'images')\n",
    "# images.mkdir(parents=True, exist_ok=True)\n",
    "# Path(dir / 'train_images').rename(dir / 'images' / 'train')\n",
    "# Path(dir / 'val_images').rename(dir / 'images' / 'val')\n",
    "\n",
    "# # Split\n",
    "# autosplit(dir / 'images' / 'train')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading xView\\xView_train.geojson...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting xView\\xView_train.geojson:  12%|█▏        | 74061/601937 [00:01<00:07, 71686.78it/s]C:\\Users\\rishi\\AppData\\Local\\Temp\\ipykernel_4196\\2148063330.py:36: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  box = xyxy2xywhn(box[None].astype(np.float), w=shapes[id][0], h=shapes[id][1], clip=True)\n",
      "Converting xView\\xView_train.geojson:  27%|██▋       | 161723/601937 [00:11<01:08, 6443.85it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: skipping one label for xView\\train_images\\1052.tif: incorrect class index -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting xView\\xView_train.geojson:  50%|████▉     | 298186/601937 [00:20<00:09, 33339.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: skipping one label for xView\\train_images\\1121.tif: incorrect class index -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting xView\\xView_train.geojson:  61%|██████    | 366627/601937 [00:33<00:47, 4909.44it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: skipping one label for xView\\train_images\\1211.tif: incorrect class index -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting xView\\xView_train.geojson:  82%|████████▏ | 491721/601937 [00:39<00:01, 55170.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: skipping one label for xView\\train_images\\1178.tif: incorrect class index -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting xView\\xView_train.geojson:  83%|████████▎ | 498662/601937 [00:40<00:07, 13183.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: skipping one label for xView\\train_images\\1184.tif: incorrect class index -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting xView\\xView_train.geojson:  97%|█████████▋| 585125/601937 [00:51<00:01, 8841.66it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: skipping one label for xView\\train_images\\107.tif: incorrect class index -1\n",
      "WARNING: skipping one label for xView\\train_images\\107.tif: incorrect class index -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting xView\\xView_train.geojson:  98%|█████████▊| 590384/601937 [00:52<00:01, 7502.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: skipping one label for xView\\train_images\\109.tif: incorrect class index -1\n",
      "WARNING: skipping one label for xView\\train_images\\109.tif: incorrect class index -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting xView\\xView_train.geojson: 100%|██████████| 601937/601937 [00:54<00:00, 10978.00it/s]\n"
     ]
    }
   ],
   "source": [
    "convert_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = []\n",
    "for root, dir, files in os.walk(\"xView\\\\labels\\\\train\"):\n",
    "    for file in files:\n",
    "        all_labels.append(file.split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for root, dir, files in os.walk(\"xView\\\\train_images\"):\n",
    "    for file in files:\n",
    "        img_name = file.split('.')[0]\n",
    "        if img_name in all_labels:\n",
    "            shutil.copy2(os.path.join(root, file), 'xView/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from shapely.geometry import Polygon\n",
    "import glob\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "from shutil import copyfile\n",
    " \n",
    "\n",
    "def tiler(imnames, newpath, falsepath, slice_size, ext):\n",
    "    for imname in tqdm(imnames):\n",
    "        try:\n",
    "            im = Image.open(imname)\n",
    "            imr = np.array(im, dtype=np.uint8)\n",
    "            height = imr.shape[0]\n",
    "            width = imr.shape[1]\n",
    "            labname = imname.replace(ext, '.txt')\n",
    "            labels = pd.read_csv(labname, sep=' ', names=['class', 'x1', 'y1', 'w', 'h'])\n",
    "            \n",
    "            # we need to rescale coordinates from 0-1 to real image height and width\n",
    "            labels[['x1', 'w']] = labels[['x1', 'w']] * width\n",
    "            labels[['y1', 'h']] = labels[['y1', 'h']] * height\n",
    "            \n",
    "            boxes = []\n",
    "            \n",
    "            # convert bounding boxes to shapely polygons. We need to invert Y and find polygon vertices from center points\n",
    "            for row in labels.iterrows():\n",
    "                x1 = row[1]['x1'] - row[1]['w']/2\n",
    "                y1 = (height - row[1]['y1']) - row[1]['h']/2\n",
    "                x2 = row[1]['x1'] + row[1]['w']/2\n",
    "                y2 = (height - row[1]['y1']) + row[1]['h']/2\n",
    "\n",
    "                boxes.append((int(row[1]['class']), Polygon([(x1, y1), (x2, y1), (x2, y2), (x1, y2)])))\n",
    "            \n",
    "            counter = 0\n",
    "            # create tiles and find intersection with bounding boxes for each tile\n",
    "            for i in range((height // slice_size)):\n",
    "                for j in range((width // slice_size)):\n",
    "                    x1 = j*slice_size\n",
    "                    y1 = height - (i*slice_size)\n",
    "                    x2 = ((j+1)*slice_size) - 1\n",
    "                    y2 = (height - (i+1)*slice_size) + 1\n",
    "\n",
    "                    pol = Polygon([(x1, y1), (x2, y1), (x2, y2), (x1, y2)])\n",
    "                    imsaved = False\n",
    "                    slice_labels = []\n",
    "\n",
    "                    for box in boxes:\n",
    "                        if pol.intersects(box[1]):\n",
    "                            inter = pol.intersection(box[1])        \n",
    "                            \n",
    "                            if not imsaved:\n",
    "                                sliced = imr[i*slice_size:(i+1)*slice_size, j*slice_size:(j+1)*slice_size]\n",
    "                                sliced_im = Image.fromarray(sliced)\n",
    "                                filename = imname.split('/')[-1]\n",
    "                                slice_path = newpath + \"/\" + filename.replace(ext, f'_{i}_{j}{ext}')                            \n",
    "                                slice_labels_path = newpath + \"/\" + filename.replace(ext, f'_{i}_{j}.txt')                            \n",
    "                                sliced_im.save(slice_path)\n",
    "                                imsaved = True                    \n",
    "                            \n",
    "                            # get smallest rectangular polygon (with sides parallel to the coordinate axes) that contains the intersection\n",
    "                            new_box = inter.envelope \n",
    "                            \n",
    "                            # get central point for the new bounding box \n",
    "                            centre = new_box.centroid\n",
    "                            \n",
    "                            # get coordinates of polygon vertices\n",
    "                            x, y = new_box.exterior.coords.xy\n",
    "                            \n",
    "                            # get bounding box width and height normalized to slice size\n",
    "                            new_width = (max(x) - min(x)) / slice_size\n",
    "                            new_height = (max(y) - min(y)) / slice_size\n",
    "                            \n",
    "                            # we have to normalize central x and invert y for yolo format\n",
    "                            new_x = (centre.coords.xy[0][0] - x1) / slice_size\n",
    "                            new_y = (y1 - centre.coords.xy[1][0]) / slice_size\n",
    "                            \n",
    "                            counter += 1\n",
    "\n",
    "                            slice_labels.append([box[0], new_x, new_y, new_width, new_height])\n",
    "                    \n",
    "                    if len(slice_labels) > 0:\n",
    "                        slice_df = pd.DataFrame(slice_labels, columns=['class', 'x1', 'y1', 'w', 'h'])\n",
    "                        slice_df.to_csv(slice_labels_path, sep=' ', index=False, header=False, float_format='%.6f')\n",
    "                    \n",
    "                    if not imsaved and falsepath:\n",
    "                        sliced = imr[i*slice_size:(i+1)*slice_size, j*slice_size:(j+1)*slice_size]\n",
    "                        sliced_im = Image.fromarray(sliced)\n",
    "                        filename = imname.split('/')[-1]\n",
    "                        slice_path = falsepath + \"/\" + filename.replace(ext, f'_{i}_{j}{ext}')                \n",
    "\n",
    "                        sliced_im.save(slice_path)\n",
    "                        print('Slice without boxes saved')\n",
    "                        imsaved = True\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = []\n",
    "for root, dir, files in os.walk(\"tiling\\comb_files\"):\n",
    "    for file in files:\n",
    "        if file.split('.')[-1] == \"tif\":\n",
    "            all_files.append(os.path.join(root, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:48<00:00,  2.44it/s]\n"
     ]
    }
   ],
   "source": [
    "tiler(all_files, 'tiling/sliced', None, 512, '.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_imgs = [i.split('.')[0] for i in os.listdir('xview_sliced\\images')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(all_imgs, test_size=0.1, random_state=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8118, 902)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9020/9020 [01:02<00:00, 143.43it/s]\n"
     ]
    }
   ],
   "source": [
    "for root, dir, files in os.walk(\"xview_sliced\\images\"):\n",
    "    for file in tqdm(files):\n",
    "        img_name = file.split('.')[0]\n",
    "        file_path = os.path.join(root, file)\n",
    "        if img_name in train:\n",
    "            shutil.copy2(file_path, 'xview_sliced\\\\train')\n",
    "        elif img_name in test:\n",
    "            shutil.copy2(file_path, 'xview_sliced\\\\val')\n",
    "        else:\n",
    "            print('error_occ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9016/9016 [00:34<00:00, 260.16it/s]\n"
     ]
    }
   ],
   "source": [
    "for root, dir, files in os.walk(\"xview_sliced\\labels\"):\n",
    "    for file in tqdm(files):\n",
    "        img_name = file.split('.')[0]\n",
    "        file_path = os.path.join(root, file)\n",
    "        if img_name in train:\n",
    "            shutil.copy2(file_path, 'xview_sliced\\\\train')\n",
    "        elif img_name in test:\n",
    "            shutil.copy2(file_path, 'xview_sliced\\\\val')\n",
    "        else:\n",
    "            print('error_occ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8118/8118 [00:00<00:00, 16139.19it/s]\n"
     ]
    }
   ],
   "source": [
    "for root, dir, files in os.walk(\"D:\\RedPositive Internship\\Multiclass\\yolov7\\custom_dataset\\images\\\\train\"):\n",
    "    for file in tqdm(files):\n",
    "        # img_name = file.split('.')[0]\n",
    "        file_path = os.path.join(root, file)\n",
    "        with open('custom_dataset\\\\train.txt', 'a') as f:\n",
    "            f.write(file_path + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('custom_dataset\\classes.names') as f:\n",
    "    data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  0: Fixed-wing Aircraft  1: Small Aircraft  2: Cargo Plane  3: Helicopter  4: Passenger Vehicle  5: Small Car  6: Bus  7: Pickup Truck  8: Utility Truck  9: Truck  10: Cargo Truck  11: Truck w/Box  12: Truck Tractor  13: Trailer  14: Truck w/Flatbed  15: Truck w/Liquid  16: Crane Truck  17: Railway Vehicle  18: Passenger Car  19: Cargo Car  20: Flat Car  21: Tank car  22: Locomotive  23: Maritime Vessel  24: Motorboat  25: Sailboat  26: Tugboat  27: Barge  28: Fishing Vessel  29: Ferry  30: Yacht  31: Container Ship  32: Oil Tanker  33: Engineering Vehicle  34: Tower crane  35: Container Crane  36: Reach Stacker  37: Straddle Carrier  38: Mobile Crane  39: Dump Truck  40: Haul Truck  41: Scraper/Tractor  42: Front loader/Bulldozer  43: Excavator  44: Cement Mixer  45: Ground Grader  46: Hut/Tent  47: Shed  48: Building  49: Aircraft Hangar  50: Damaged Building  51: Facility  52: Construction Site  53: Vehicle Lot  54: Helipad  55: Storage Tank  56: Shipping container lot  57: Shipping Container  58: Pylon  59: Tower'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('yolo_pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4b71bb9b09c4c6f7c4f98fa48cdcc5ebf0cd9907f58a7dc376fc6023b0f69e97"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
